//#define PACKETDUMP
using System;
using System.Collections.Generic;
using System.Text;
using System.Diagnostics;
using System.IO;

namespace ICSimulator
{
    public class SchedBuf
    {
        public MemoryRequest mreq=null;
        public ulong whenArrived=ulong.MaxValue;
        public ulong whenStarted=ulong.MaxValue;
        public ulong whenCompleted=ulong.MaxValue;
        public ulong whenIdle=0; // for sub-commands
        public bool moreCommands = true;
        public int index = -1;
        public uint burstLength = 4;
        public bool issuedActivation=false;
        public bool marked=false;
        public int rank=-1;

        protected DRAM mem;

	/* HWA CODE */
	public int wait_num=0;
	/* HWA CODE END */

        public SchedBuf(int index, DRAM mem)
        {
            this.index = index;
            this.mem = mem;
        }

        public void Allocate(MemoryRequest mreq)
        {
            this.mreq = mreq;
            mreq.buf_index = index;
            whenArrived = Simulator.CurrentRound;
            moreCommands = true;
            burstLength = mreq.mem_size / Config.memory.busWidth / 2;
        }

	/* HWA CODE */
	public void print_stat(int id)
	{
	    if( Simulator.network.nodes[mreq.request.requesterID].cpu.is_HWA() )
		Console.WriteLine("{0}-{4}:, {1},{2},{3}", mreq.request.requesterID, whenStarted-whenArrived, whenCompleted-whenStarted,wait_num,id);
	}

        public void Deallocate()
        {
            mreq.buf_index = -1;
            mreq=null;
            whenArrived=ulong.MaxValue;
            whenStarted=ulong.MaxValue;
            whenCompleted=ulong.MaxValue;
            whenIdle = 0;
            issuedActivation = false;
            marked = false;
            rank = -1;
	    /* HWA CODE */
	    wait_num=0;
	    /* HWA CODE END */
        }

        protected ulong Now { get { return Simulator.CurrentRound; } }

        public bool IsOlderThan(SchedBuf other)
        {
            return whenArrived < other.whenArrived;
        }
        public bool IsRowBufferHit { get { return mem.ranks[mreq.rank_index].banks[mreq.bank_index].IsOpen(mreq.shift_row); } }
        public bool FromGPU { get { return mreq.from_GPU;} }
        public bool IsWrite { get { return mreq.request.write; } }

        public bool Available { get { return mreq == null; } }
        public bool Valid { get { return mreq != null; } }
        public bool Started { get { return whenStarted <= Now; } }
        public bool Completed { get { return whenCompleted <= Now; } }
        public bool Busy { get { return whenIdle > Now; } }
        public bool Urgent { get { return mreq.from_GPU?((Now-whenArrived) >= (ulong)Config.memory.GPUUrgentThreshold):
                                                        ((Now-whenArrived) >= (ulong)Config.memory.coreUrgentThreshold); } }
        public bool SuperUrgent { get { return (Now-whenArrived) >= (ulong)Config.memory.SuperUrgentThreshold; } }
    }

    abstract public class Scheduler
    {
        public SchedBuf[] buf = null;
        protected DRAM mem = null;
        protected Channel chan = null;

        protected ulong lastIssue = 0;
        protected ulong Now { get { return Simulator.CurrentRound; } }

	/* HWA CODE */
	public SchedBuf winner;
	/* HWA CODE END */

        // TODO:
        // To decide whether to cache a row or not...
        // Policy 1: Don't do it unless you're sure: scan SchedBuf and if there's more than one request for
        //           the row, then go ahead and cache it.
        // Policy 2: Each core gets a row.  If the row is not in use, is clean (no WB needed), or is too old,
        //           then cache it.  For additional (non-per-core), if no pending requests for that row, row
        //           is clean or too old, then cache it.
        // Policy 2b: Same as 2, but potentially steal rows from other cores if they are clean and old, or
        //            dirty and very, very old.
        // Policy 2c: variant of 2b: add a relative utility counter to each row.  Increment on each hit, and
        //            also track the number of requests overall by that core.  This judges how useful caching
        //            that row is relative to the request rate of that row.  Age (>>=1) when the overall
        //            request rate saturates its counter. If below threshold, allow other cores to steal.
        //            If above threshold, give preference for allocating non-core entries.
        // Coarse-control: If core consistently does not make good use of its cache entries, stop caching
        // any of its lines.

        // TODO: scheduling policies...
        // Policy 1: Simple RBRF hit first, RB hit first, FCFS
        // Policy 1b: Read first, RBRF hit first, RB hit first, FCFS
        // Policy 2: Keep tracking which requests would like to cache their rows, and schedule RBRF hits
        //           to same entry first to allow the entry to be reused sooner.

        public Scheduler()
        {
        }

        public Scheduler(SchedBuf[] buf, DRAM mem, Channel chan)
        {
            this.buf = buf;
            this.mem = mem;
            this.chan = chan;
        }

        // Override this for other algorithms
        virtual protected SchedBuf Pick(SchedBuf winner, SchedBuf candidate)
        {
            if(winner == null)
                winner = candidate;
            else if(!winner.IsRowBufferHit && candidate.IsRowBufferHit) // prev not RB hit
                winner = candidate;
            else if(candidate.IsOlderThan(winner))
                winner = candidate;
            return winner;
        }

	/* HWA CODE */
	// Override this for other algorithms
	virtual protected bool schedMaskCheck(SchedBuf tgt)
	{
	    return true;
	}
	virtual protected void schedMaskPrepare()
	{
	    return;
	}
	virtual protected bool schedResultMaskChk(SchedBuf tgt)
	{
	    return true;
	}
	virtual public void calculate_priority()
	{
	    return;
	}
	virtual public int getPriority(int id)
	{
	    return 0;
	}
	/* HWA CODE END */

        // Override this for other algorithms
        virtual public void Tick()
        {
            mem.Tick();
#if PACKETDUMP
	    Console.WriteLine("In sched.tick");
#endif
	    /* HWA CODE Comment Out */
	    /*
            SchedBuf winner = null;
	    */
	    /* HWA Code Comment Out End */
	    /* HWA CODE */
	    winner = null;
	    schedMaskPrepare();
	    /* HWA CODE END */		    
            for(int i=0;i<buf.Length;i++)
            {
#if PACKETDUMP
                    Console.WriteLine("buf_valid = {0}, buf_busy = {1}, buf_morecommand = {2}, buf num = {3}",buf[i].Valid, buf[i].moreCommands, buf[i].Busy, i);
#endif
 
                if(buf[i].Valid && buf[i].moreCommands && !buf[i].Busy)
                {
                    bool DBAvailable = buf[i].IsWrite ? (chan.writeRequests < chan.maxWrites) : (chan.readRequests < chan.maxReads);
#if PACKETDUMP
                    Console.WriteLine("in scheduler, DB_avail = {0}, at buffer location {1}, iswrite = {2}",DBAvailable,i,buf[i].IsWrite);
#endif
		    /* HWA CODE */
//                    if(DBAvailable && mem.RequestCanIssue(buf[i]))
                    if(DBAvailable && mem.RequestCanIssue(buf[i]) && schedMaskCheck(buf[i]))
		    	/* HWA CODE END */
		    {
			/* HWA CODE */
			SchedBuf winner_bak = winner;
			/* HWA CODE END */
                        winner = Pick(winner,buf[i]);

			/* HWA CODE */
			if( winner != null )
			{
			    if( winner != buf[i] )
			    {
				buf[i].wait_num++;
//				if( buf[i].mreq.request.requesterID == 17 )
//				    Console.WriteLine("WinnerID:{0}", winner.mreq.request.requesterID );
			    }
			    else if( winner_bak != null )
				winner_bak.wait_num++;
			}
			/* HWA CODE END */
		    }
                }
            }

	    if( winner != null )
		if( !schedResultMaskChk(winner) ) winner = null;  // 

            if(winner != null)
            {
                if(winner.whenStarted == ulong.MaxValue)
                    winner.whenStarted = Simulator.CurrentRound;
                if(winner.Urgent)
                    Simulator.stats.DRAMUrgentCommandsPerSrc[winner.mreq.request.requesterID].Add();
                Simulator.stats.DRAMCommandsPerSrc[winner.mreq.request.requesterID].Add();
                mem.IssueCommand(winner);
                if(!winner.moreCommands && winner.marked)
                    MarkCompleted(winner);
                chan.lastBankActivity[winner.mreq.rank_index,winner.mreq.bank_index] = Now;
                lastIssue = Now;
		/* HWA CODE */
		if( !winner.moreCommands )
		{
		    if( Simulator.network.nodes[winner.mreq.request.requesterID].cpu.is_HWA() )
			chan.HWAUnIssueRequests--;
		    chan.unIssueRequestsPerCore[winner.mreq.request.requesterID]--;
		    Simulator.QoSCtrl.bw_increment(winner.mreq.request.requesterID);
		}
		/* HWA CODE END */
            }
        }

        virtual public void MarkCompleted(SchedBuf buf)
        {
        }

        public bool IsCurrentlyRequested(ulong pageIndex)
        {
            for(int i=0;i<buf.Length;i++)
            {
                if(buf[i].Valid && buf[i].moreCommands && buf[i].mreq.shift_row == pageIndex)
                    return true;
            }
            return false;
        }

        public int NumSameRequests(ulong pageIndex)
        {
            int reqs = 0;
            for(int i=0;i<buf.Length;i++)
            {
                if(buf[i].Valid && buf[i].moreCommands && buf[i].mreq.shift_row == pageIndex)
                    reqs++;
            }
            return reqs;
        }
    }
}
